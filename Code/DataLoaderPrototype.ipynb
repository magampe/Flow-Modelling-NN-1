{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# Pytorch package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from  torchvision.transforms import ToTensor, Compose, Normalize, Resize\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code sourced from: https://github.com/rasbt/stat453-deep-learning-ss21/blob/main/L09/code/custom-dataloader/custom-dataloader-example.ipynb\n",
    "\n",
    "tutorial at: https://www.youtube.com/watch?v=hPzJ8H0Jtew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train, validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 File Name  Discharge (Mean)\n",
      "0  PRISM_ppt_stable_4kmD2_20220401_bil.tif             221.0\n",
      "1  PRISM_ppt_stable_4kmD2_20220402_bil.tif             184.0\n",
      "2  PRISM_ppt_stable_4kmD2_20220403_bil.tif             159.0\n",
      "3  PRISM_ppt_stable_4kmD2_20220404_bil.tif             140.0\n",
      "4  PRISM_ppt_stable_4kmD2_20220405_bil.tif             129.0 \n",
      " 91 \n",
      " <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./mlp_data/Q2_2022_ppt_target_full.csv\")\n",
    "df.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "print(df[:5],\"\\n\", len(df), \"\\n\", type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 18 17\n"
     ]
    }
   ],
   "source": [
    "train = df[:56]\n",
    "valid = df[56:74]\n",
    "test = df[74:]\n",
    "print(len(train),len(valid),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"./mlp_data/Q2_2022_ppt_target_train.csv\")\n",
    "valid.to_csv(\"./mlp_data/Q2_2022_ppt_target_valid.csv\")\n",
    "test.to_csv(\"./mlp_data/Q2_2022_ppt_target_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 18 17\n"
     ]
    }
   ],
   "source": [
    "train_img_dir = os.listdir(\"./PPT_DATA_Clipped_Q2_2022_copy/train\")\n",
    "train_img_dir = pd.DataFrame(train_img_dir, columns=[\"File Name\"])\n",
    "\n",
    "valid_img_dir = os.listdir(\"./PPT_DATA_Clipped_Q2_2022_copy/validation\")\n",
    "valid_img_dir = pd.DataFrame(valid_img_dir, columns=[\"File Name\"])\n",
    "\n",
    "test_img_dir = os.listdir(\"./PPT_DATA_Clipped_Q2_2022_copy/test\")\n",
    "test_img_dir = pd.DataFrame(test_img_dir, columns=[\"File Name\"])\n",
    "\n",
    "print(len(train_img_dir), len(valid_img_dir), len(test_img_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Arguments for Custom Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 File Name\n",
      "0  PRISM_ppt_stable_4kmD2_20220401_bil.tif\n",
      "1  PRISM_ppt_stable_4kmD2_20220402_bil.tif\n",
      "2  PRISM_ppt_stable_4kmD2_20220403_bil.tif\n",
      "3  PRISM_ppt_stable_4kmD2_20220404_bil.tif\n",
      "4  PRISM_ppt_stable_4kmD2_20220405_bil.tif \n",
      " <class 'pandas.core.frame.DataFrame'> \n",
      "                                  File Name  Discharge (Mean)\n",
      "0  PRISM_ppt_stable_4kmD2_20220401_bil.tif             221.0\n",
      "1  PRISM_ppt_stable_4kmD2_20220402_bil.tif             184.0\n",
      "2  PRISM_ppt_stable_4kmD2_20220403_bil.tif             159.0\n",
      "3  PRISM_ppt_stable_4kmD2_20220404_bil.tif             140.0\n",
      "4  PRISM_ppt_stable_4kmD2_20220405_bil.tif             129.0 \n",
      " <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_img_dir[:5], \"\\n\", type(train_img_dir), \"\\n\", train[0:5], \"\\n\", type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['File Name']\n",
    "        self.y = df['Discharge (Mean)']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Add channel for T-mean\n",
    "\n",
    "        # Open the geospatial file using Rasterio\n",
    "        with rasterio.open(os.path.join(self.img_dir + self.img_names[idx]), 'r') as src:\n",
    "            data = src.read(1)  # Read the data (e.g., satellite imagery)\n",
    "            # Apply any preprocessing or transformations here\n",
    "            if self.transform:\n",
    "                data = self.transform(data)\n",
    "        discharge = self.y[idx]\n",
    "        return data, discharge\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(csv_path='./mlp_data/Q2_2022_ppt_target_train.csv',\n",
    "                          img_dir='./PPT_DATA_Clipped_Q2_2022_copy/train/',\n",
    "                          transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = MyDataset(csv_path='./mlp_data/Q2_2022_ppt_target_valid.csv',\n",
    "                          img_dir='./PPT_DATA_Clipped_Q2_2022_copy/validation/',\n",
    "                          transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(csv_path='./mlp_data/Q2_2022_ppt_target_test.csv',\n",
    "                          img_dir='./PPT_DATA_Clipped_Q2_2022_copy/test/',\n",
    "                          transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=1,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=1,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=1,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 1 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 2 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 3 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 4 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 5 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 6 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 7 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 8 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 9 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 10 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 11 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 12 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 13 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 14 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 15 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 16 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 17 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 18 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 19 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 20 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 21 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 22 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 23 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 24 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 25 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 26 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 27 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 28 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 29 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 30 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 31 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 32 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 33 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 34 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 35 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 36 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 37 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 38 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 39 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 40 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 41 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 42 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 43 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 44 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 45 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 46 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 47 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 48 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 49 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 50 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 51 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 52 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 53 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 54 | Batch size: 1\n",
      "Epoch: 1 | Batch index: 55 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 1 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 2 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 3 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 4 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 5 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 6 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 7 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 8 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 9 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 10 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 11 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 12 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 13 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 14 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 15 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 16 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 17 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 18 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 19 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 20 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 21 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 22 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 23 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 24 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 25 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 26 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 27 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 28 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 29 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 30 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 31 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 32 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 33 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 34 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 35 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 36 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 37 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 38 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 39 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 40 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 41 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 42 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 43 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 44 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 45 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 46 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 47 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 48 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 49 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 50 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 51 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 52 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 53 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 54 | Batch size: 1\n",
      "Epoch: 2 | Batch index: 55 | Batch size: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1, 1, 8, 8])\n",
      "Labels batch shape: torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXhElEQVR4nO3df2xV9f3H8ddtu16I9l4pUqDjUpDhELEdo0JYdU6pkoYQ9Q9GCGblx5ZILgNsTAz/rP7FZVm2uC2kA1yKiSO4mYFKUrrCpMQIoUCagEsQlEknQnWRe9v+cTG9Z395v98GuNxze9/39Fyej+Qk3us5Pe9U7JNzPm1PwHEcRwAA5FmJ1wMAAIoTgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACbKCn3CVCqlK1euqKKiQoFAoNCnBwCMguM4GhgYUHV1tUpKMl+jFDwwV65cUSQSKfRpAQB51NfXp2nTpmXcp+C3yCoqKgp9SgBAnmXztbzggeG2GAD4XzZfy1nkBwCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADARE6B2bFjh2bMmKFx48Zp0aJFOnnyZL7nAgD4nOvAvPXWW2ppaVFra6vOnDmjuro6LV26VP39/RbzAQD8ynFp4cKFTjQaTb8eHh52qqurnVgsltXx8XjckcTGxsbG5uMtHo/f8eu9qyuYGzdu6PTp02psbEy/V1JSosbGRh0/fvyWxySTSSUSiREbAKD4uQrMV199peHhYU2ePHnE+5MnT9bVq1dveUwsFlM4HE5vkUgk92kBAL5h/l1kW7duVTweT299fX3WpwQAjAFlbna+//77VVpaqmvXro14/9q1a5oyZcotjwkGgwoGg7lPCADwJVdXMOXl5VqwYIGOHDmSfi+VSunIkSNavHhx3ocDAPiXqysYSWppaVFzc7Pq6+u1cOFCvfbaaxoaGtLatWst5gMA+JTrwKxcuVJffvmlfvWrX+nq1av6wQ9+oEOHDt208A8AuLsFHMdxCnnCRCKhcDhcyFMCAPIsHo8rFApl3IffRQYAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMuH7gGIDiVeDHQ8GH3DzTiysYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcB+bYsWNavny5qqurFQgEdODAAYOxAAB+5zowQ0NDqqur044dOyzmAQAUiTK3BzQ1NampqcliFgBAEXEdGLeSyaSSyWT6dSKRsD4lAGAMMF/kj8ViCofD6S0SiVifEgAwBpgHZuvWrYrH4+mtr6/P+pQAgDHA/BZZMBhUMBi0Pg0AYIzh52AAACZcX8EMDg7q4sWL6deXLl1Sb2+vKisrNX369LwOBwDwr4DjOI6bA44ePaonn3zypvebm5u1Z8+eOx6fSCQUDofdnBJAgbj8coC70Ldfw+PxuEKhUMZ9XV/B/OQnP+EPIQDgjliDAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcPw8GKCSePQT4F1cwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEy4CkwsFtOjjz6qiooKVVVV6bnnntP58+etZgMA+JirwHR3dysajerEiRPq6urSN998o2eeeUZDQ0NW8wEAfCrgOI6T68Fffvmlqqqq1N3drR//+MdZHZNIJBQOh3M9Je4yo/jjCcDAt1/D4/G4QqFQxn3LRnOieDwuSaqsrLztPslkUslkcsRwAIDil/MifyqV0pYtW9TQ0KB58+bddr9YLKZwOJzeIpFIrqcEAPhIzrfINmzYoI6ODn3wwQeaNm3abfe71RUMkUG2uEUGjC3mt8g2btyogwcP6tixYxnjIknBYFDBYDCX0wAAfMxVYBzH0S9/+Uvt379fR48e1cyZM63mAgD4nKvARKNR7d27V++8844qKip09epVSVI4HNb48eNNBgQA+JOrNZhAIHDL99vb27VmzZqsPgbfpgw3WIMBxhazNRj+ZwcAZIvfRQYAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAlXDxyDP/GgOGDsut2TgosBVzAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGDCVWDa2tpUW1urUCikUCikxYsXq6Ojw2o2AICPuQrMtGnTtH37dp0+fVqnTp3SU089pWeffVYfffSR1XwAAJ8KOI7jjOYDVFZW6je/+Y3Wr1+f1f6JRELhcHg0p4RLo/xPDMBQIBDweoScxONxhUKhjPuU5frBh4eH9be//U1DQ0NavHjxbfdLJpNKJpPp14lEItdTAgB8xPUi/9mzZ3XvvfcqGAzqxRdf1P79+zV37tzb7h+LxRQOh9NbJBIZ1cAAAH9wfYvsxo0bunz5suLxuN5++229/vrr6u7uvm1kbnUFQ2QKi1tkwNhVzLfIRr0G09jYqFmzZmnnzp1Z7c8aTOERGGDsKubAjPrnYFKp1IgrFAAAJJeL/Fu3blVTU5OmT5+ugYEB7d27V0ePHlVnZ6fVfAAAn3IVmP7+fv3sZz/TF198oXA4rNraWnV2durpp5+2mg8A4FOjXoNxizWYwmMNBhi7WIMBAMAlAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMuHqi5d2OB3cBQPa4ggEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABOjCsz27dsVCAS0ZcuWPI0DACgWOQemp6dHO3fuVG1tbT7nAQAUiZwCMzg4qNWrV2v37t2aMGFCvmcCABSBnAITjUa1bNkyNTY25nseAECRKHN7wL59+3TmzBn19PRktX8ymVQymUy/TiQSbk8JAPAhV1cwfX192rx5s/7yl79o3LhxWR0Ti8UUDofTWyQSyWlQAIC/BBzHcbLd+cCBA3r++edVWlqafm94eFiBQEAlJSVKJpMj/p106ysYv0bGxacKALISCAS8HiEn8XhcoVAo4z6ubpEtWbJEZ8+eHfHe2rVrNWfOHL3yyis3xUWSgsGggsGgm9MAAIqAq8BUVFRo3rx5I9675557NHHixJveBwDc3fhJfgCACVdrMPmQSCQUDocLecq8YQ0GQL4V8xoMVzAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJhw9chkANnx60OkgHziCgYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACVeBefXVVxUIBEZsc+bMsZoNAOBjZW4PePjhh3X48OH/+wBlrj8EAOAu4LoOZWVlmjJlisUsAIAi4noN5sKFC6qurtYDDzyg1atX6/Llyxn3TyaTSiQSIzYAQPFzFZhFixZpz549OnTokNra2nTp0iU9/vjjGhgYuO0xsVhM4XA4vUUikVEPDQAY+wKO4zi5Hnz9+nXV1NTod7/7ndavX3/LfZLJpJLJZPp1IpHwbWRG8anCXSYQCHg9AmAqHo8rFApl3GdUK/T33XefHnzwQV28ePG2+wSDQQWDwdGcBgDgQ6P6OZjBwUF98sknmjp1ar7mAQAUCVeBefnll9Xd3a1///vf+vDDD/X888+rtLRUq1atspoPAOBTrm6R/ec//9GqVav03//+V5MmTdJjjz2mEydOaNKkSVbzAQB8alSL/LlIJBIKh8OFPGXesMiPbLHIj2KXzSI/v4sMAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmHD1wDGg0HiuCuBfXMEAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOE6MJ9//rleeOEFTZw4UePHj9cjjzyiU6dOWcwGAPCxMjc7f/3112poaNCTTz6pjo4OTZo0SRcuXNCECROs5gMA+JSrwPz6179WJBJRe3t7+r2ZM2fmfSgAgP+5ukX27rvvqr6+XitWrFBVVZXmz5+v3bt3ZzwmmUwqkUiM2AAAxc9VYD799FO1tbVp9uzZ6uzs1IYNG7Rp0ya98cYbtz0mFospHA6nt0gkMuqhAQBjX8BxHCfbncvLy1VfX68PP/ww/d6mTZvU09Oj48eP3/KYZDKpZDKZfp1IJHwbGRefKuRJIBDwegQAtxCPxxUKhTLu4+oKZurUqZo7d+6I9x566CFdvnz5tscEg0GFQqERGwCg+LkKTENDg86fPz/ivY8//lg1NTV5HQoA4H+uAvPSSy/pxIkT2rZtmy5evKi9e/dq165dikajVvMBAHzK1RqMJB08eFBbt27VhQsXNHPmTLW0tOgXv/hF1scnEgmFw2HXg44FrMEUHmswwNiUzRqM68CMFoGBGwQGGJvyvsgPAEC2CAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwUeb1AH7Cw68AIHtcwQAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAlXgZkxY4YCgcBNWzQatZoPAOBTZW527unp0fDwcPr1uXPn9PTTT2vFihV5HwwA4G+uAjNp0qQRr7dv365Zs2bpiSeeyOtQAAD/cxWY/+/GjRt688031dLSokAgcNv9ksmkkslk+nUikcj1lAAAH8l5kf/AgQO6fv261qxZk3G/WCymcDic3iKRSK6nBAD4SMBxHCeXA5cuXary8nK99957Gfe71RUMkQEAf4vH4wqFQhn3yekW2WeffabDhw/r73//+x33DQaDCgaDuZwGAOBjOd0ia29vV1VVlZYtW5bveQAARcJ1YFKplNrb29Xc3Kyyspy/RwAAUORcB+bw4cO6fPmy1q1bZzEPAKBI5LzIn6tEIqFwOFzIUwIA8iybRX5+FxkAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwUfDAFPjxMwAAA9l8LS94YAYGBgp9SgBAnmXztbzgT7RMpVK6cuWKKioqFAgE8vqxE4mEIpGI+vr67viktbGEuQuLuQvPr7Mz980cx9HAwICqq6tVUpL5GqUsr2fOQklJiaZNm2Z6jlAo5Ks/DN9i7sJi7sLz6+zMPVK2j71nkR8AYILAAABMFFVggsGgWltbFQwGvR7FFeYuLOYuPL/OztyjU/BFfgDA3aGormAAAGMHgQEAmCAwAAATBAYAYKJoArNjxw7NmDFD48aN06JFi3Ty5EmvR7qjY8eOafny5aqurlYgENCBAwe8HikrsVhMjz76qCoqKlRVVaXnnntO58+f93qsO2pra1NtbW36h88WL16sjo4Or8dybfv27QoEAtqyZYvXo2T06quvKhAIjNjmzJnj9VhZ+fzzz/XCCy9o4sSJGj9+vB555BGdOnXK67HuaMaMGTd9zgOBgKLRqCfzFEVg3nrrLbW0tKi1tVVnzpxRXV2dli5dqv7+fq9Hy2hoaEh1dXXasWOH16O40t3drWg0qhMnTqirq0vffPONnnnmGQ0NDXk9WkbTpk3T9u3bdfr0aZ06dUpPPfWUnn32WX300Udej5a1np4e7dy5U7W1tV6PkpWHH35YX3zxRXr74IMPvB7pjr7++ms1NDToO9/5jjo6OvSvf/1Lv/3tbzVhwgSvR7ujnp6eEZ/vrq4uSdKKFSu8GcgpAgsXLnSi0Wj69fDwsFNdXe3EYjEPp3JHkrN//36vx8hJf3+/I8np7u72ehTXJkyY4Lz++utej5GVgYEBZ/bs2U5XV5fzxBNPOJs3b/Z6pIxaW1uduro6r8dw7ZVXXnEee+wxr8fIi82bNzuzZs1yUqmUJ+f3/RXMjRs3dPr0aTU2NqbfKykpUWNjo44fP+7hZHePeDwuSaqsrPR4kuwNDw9r3759Ghoa0uLFi70eJyvRaFTLli0b8Wd9rLtw4YKqq6v1wAMPaPXq1bp8+bLXI93Ru+++q/r6eq1YsUJVVVWaP3++du/e7fVYrt24cUNvvvmm1q1bl/dfLJwt3wfmq6++0vDwsCZPnjzi/cmTJ+vq1aseTXX3SKVS2rJlixoaGjRv3jyvx7mjs2fP6t5771UwGNSLL76o/fv3a+7cuV6PdUf79u3TmTNnFIvFvB4la4sWLdKePXt06NAhtbW16dKlS3r88cfH/CM7Pv30U7W1tWn27Nnq7OzUhg0btGnTJr3xxhtej+bKgQMHdP36da1Zs8azGQr+25RRXKLRqM6dO+eLe+uS9P3vf1+9vb2Kx+N6++231dzcrO7u7jEdmb6+Pm3evFldXV0aN26c1+NkrampKf3PtbW1WrRokWpqavTXv/5V69ev93CyzFKplOrr67Vt2zZJ0vz583Xu3Dn96U9/UnNzs8fTZe/Pf/6zmpqaVF1d7dkMvr+Cuf/++1VaWqpr166NeP/atWuaMmWKR1PdHTZu3KiDBw/q/fffN38EQ76Ul5fre9/7nhYsWKBYLKa6ujr9/ve/93qsjE6fPq3+/n798Ic/VFlZmcrKytTd3a0//OEPKisr0/DwsNcjZuW+++7Tgw8+qIsXL3o9SkZTp0696S8cDz30kC9u733rs88+0+HDh/Xzn//c0zl8H5jy8nItWLBAR44cSb+XSqV05MgR39xb9xvHcbRx40bt379f//znPzVz5kyvR8pZKpVSMpn0eoyMlixZorNnz6q3tze91dfXa/Xq1ert7VVpaanXI2ZlcHBQn3zyiaZOner1KBk1NDTc9G33H3/8sWpqajyayL329nZVVVVp2bJlns5RFLfIWlpa1NzcrPr6ei1cuFCvvfaahoaGtHbtWq9Hy2hwcHDE3+YuXbqk3t5eVVZWavr06R5Ollk0GtXevXv1zjvvqKKiIr3WFQ6HNX78eI+nu72tW7eqqalJ06dP18DAgPbu3aujR4+qs7PT69EyqqiouGl965577tHEiRPH9LrXyy+/rOXLl6umpkZXrlxRa2urSktLtWrVKq9Hy+ill17Sj370I23btk0//elPdfLkSe3atUu7du3yerSspFIptbe3q7m5WWVlHn+J9+R71wz88Y9/dKZPn+6Ul5c7CxcudE6cOOH1SHf0/vvvO5Ju2pqbm70eLaNbzSzJaW9v93q0jNatW+fU1NQ45eXlzqRJk5wlS5Y4//jHP7weKyd++DbllStXOlOnTnXKy8ud7373u87KlSudixcvej1WVt577z1n3rx5TjAYdObMmePs2rXL65Gy1tnZ6Uhyzp8/7/UoDr+uHwBgwvdrMACAsYnAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMPE/4qLmm3N/g4sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 594.0\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "x_image_as_vector = x.view(-1, 8*8)\n",
    "print(x_image_as_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a basic Regression MLP with current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From local helper files\n",
    "from helper_evaluation import set_all_seeds, set_deterministic\n",
    "# from helper_train import train_model\n",
    "# from helper_plotting import plot_training_loss, plot_accuracy, show_examples\n",
    "# from helper_dataset import get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([1, 1, 8, 8])\n",
      "Corresponding Discharge dimensions: torch.Size([1])\n",
      "Discharge of 10 examples: tensor([132.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Corresponding Discharge dimensions:', labels.shape)\n",
    "    print('Discharge of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "BATCH_SIZE = 5\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(RANDOM_SEED)\n",
    "set_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, batch_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = batch_size\n",
    "        \n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(num_features, num_hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(num_hidden, batch_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### Model Initialization\n",
    "#################################\n",
    "    \n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = MLP(num_features=8*8,\n",
    "            num_hidden=100,\n",
    "            batch_size=5)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 5362.766\n",
      "Loss after mini-batch    11: 55092763936217808337632038486016.000\n",
      "Loss after mini-batch    21: 297731639574920501325495009280.000\n",
      "Loss after mini-batch    31: 131598106686792849478758957056.000\n",
      "Loss after mini-batch    41: 58166694818316421470537908224.000\n",
      "Loss after mini-batch    51: 25709823891256478164599177216.000\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 1061499733764264401397874688.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\19195\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch    11: 6962714906329823725213450240.000\n",
      "Loss after mini-batch    21: 3077537336003272645527207936.000\n",
      "Loss after mini-batch    31: 1360279270995205600430784512.000\n",
      "Loss after mini-batch    41: 601246761003622137063276544.000\n",
      "Loss after mini-batch    51: 265752561018643613615128576.000\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 10972314630884997831065600.000\n",
      "Loss after mini-batch    11: 71970909393324667247263744.000\n",
      "Loss after mini-batch    21: 31811317921391753214033920.000\n",
      "Loss after mini-batch    31: 14060677378142605999603712.000\n",
      "Loss after mini-batch    41: 6214852700906286294761472.000\n",
      "Loss after mini-batch    51: 2746979996518886408192000.000\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 113416467076525844332544.000\n",
      "Loss after mini-batch    11: 743934831038888889286656.000\n",
      "Loss after mini-batch    21: 328821039145046029369344.000\n",
      "Loss after mini-batch    31: 145339703700055792812032.000\n",
      "Loss after mini-batch    41: 64240510111993156337664.000\n",
      "Loss after mini-batch    51: 28394458933729534410752.000\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 1172342251179167186944.000\n",
      "Loss after mini-batch    11: 7689764786568408596480.000\n",
      "Loss after mini-batch    21: 3398894344921420922880.000\n",
      "Loss after mini-batch    31: 1502319464652730007552.000\n",
      "Loss after mini-batch    41: 664028883069603807232.000\n",
      "Loss after mini-batch    51: 293502361933105692672.000\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "train_loss_list = []\n",
    "for epoch in range(0, 5): # 5 epochs at maximum\n",
    "\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    \n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        train_loss_list.append(loss)\n",
    "        \n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
